{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos usando Tensorflow\n",
    "\n",
    "Cuando trabajamos con Tensorflow, existen una gran variedad de formas en las que podemos alimentar los datos a nuestra red neuronal. Esto también tiene que ver con el tipo de datos y los pasos de pre-procesamiento que sean necesarios.\n",
    "\n",
    "En la notebook 1 se utilizó un conjunto de datos de imágenes, esencialmente con variables numéricas. En esta notebook trabajemos con datos categóricos y profundizaremos en cómo trasformar los ejemplos dentro del pipeline de clasificación.\n",
    "\n",
    "Ante un problema de clasificación, lo primero que debemos hacer es **inspeccionar los datos y construir un prototipo de modelo**. La forma más fácil de hacerlo es con notebooks. Sin embargo, a la hora de llevar a cabo experimentos con redes neuronales, un entorno interactivo puede no ser la mejor opción. En primer lugar, explorar los hiperparámetros de una arquitectura neuronal puede llevar varias horas e incluso días, perdiendo todas las ventajas del entorno interactivo. En segundo lugar, no podemos encolar ejecuciones de notebooks para reservar recursos como las GPUs.\n",
    "\n",
    "Por ello, primero realizaremos una exploración inicial de los datos en esta notebook. Una vez que decidamos qué tipo de modelo implementar, pasaremos el modelo a un script de python que cargue los datos, construya el modelo, lo entrene, y finalmente guarde las métricas relevantes.\n",
    "\n",
    "En esta notebook, veremos varios conceptos avanzados de entrenamiento de redes:\n",
    "\n",
    "  * Uso de `tf.data.Dataset` para optimizar la ingesta de datos. \n",
    "  * Uso de capas `tf.layers.Embedding`.\n",
    "  * Combinación de distintos tipos de features en un mismo modelo con múltiples inputs.\n",
    "  * MLFlow para registro de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "seaborn.set_style('whitegrid')\n",
    "seaborn.set_palette('colorblind')\n",
    "seaborn.set_context('paper')\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando los datos\n",
    "\n",
    "Una vez más, estaremos trabajando con el conjunto de datos `petfinder`. Deben descargarlo siguiendo las instrucciones en la [notebook 0](./0_set_up.ipynb), descomprimirlo y luego ajustar la dirección en esta notebook según corresponda. \n",
    "\n",
    "Algunas de las preguntas que respondemos durante esta etapa son:\n",
    "\n",
    " * ¿Qué tipo de tarea tengo que resolver? ¿Clasificación o regresión?\n",
    " * ¿Qué distribución tienen mis etiquetas?\n",
    " * ¿Qué tipo de datos tengo disponible para la clasificación? ¿Cuáles son útiles?\n",
    " * Dadas las características disponibles y el problema que quiero resolver, ¿qué tipo de clasificador o arquitectura conviene utilizar? ¿De qué manera se están representando las causas latentes del problema en el modelo elegido?\n",
    " * Dadas las características disponibles y el modelo elegido, ¿de qué forma representaremos cada una de dichas características?\n",
    " \n",
    "En esta clase utilizaremos redes neuronales como modelos porque es el objetivo de la materia, pero sigue siendo importante qué aspectos podremos capturar con este tipo de modelo, especialmente para tener intuiciones sobre qué hiperparámetros explorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = '../petfinder_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset, dev_dataset = train_test_split(\n",
    "    pandas.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv')), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>Description</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>found in Bukit Tinggi Near Jusco Klang. He has...</td>\n",
       "      <td>1</td>\n",
       "      <td>9587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>41326</td>\n",
       "      <td>Pepper (and Molly)'s owner had to return back ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8218</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>- THANKS phoebe for adopting Tatam Take A Good...</td>\n",
       "      <td>1</td>\n",
       "      <td>11614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "6820     1   36     109     109       1       5       0       0             3   \n",
       "8194     1   60     195       0       2       1       0       0             1   \n",
       "8218     2    3     266     285       1       1       0       0             3   \n",
       "\n",
       "      FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  \\\n",
       "6820          2           3         3           2       2         1    0   \n",
       "8194          1           3         3           3       1         1   25   \n",
       "8218          1           2         1           2       1         1    0   \n",
       "\n",
       "      State                                        Description  AdoptionSpeed  \\\n",
       "6820  41326  found in Bukit Tinggi Near Jusco Klang. He has...              1   \n",
       "8194  41326  Pepper (and Molly)'s owner had to return back ...              0   \n",
       "8218  41326  - THANKS phoebe for adopting Tatam Take A Good...              1   \n",
       "\n",
       "        PID  \n",
       "6820   9587  \n",
       "8194  11576  \n",
       "8218  11614  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type              int64\n",
       "Age               int64\n",
       "Breed1            int64\n",
       "Breed2            int64\n",
       "Gender            int64\n",
       "Color1            int64\n",
       "Color2            int64\n",
       "Color3            int64\n",
       "MaturitySize      int64\n",
       "FurLength         int64\n",
       "Vaccinated        int64\n",
       "Dewormed          int64\n",
       "Sterilized        int64\n",
       "Health            int64\n",
       "Quantity          int64\n",
       "Fee               int64\n",
       "State             int64\n",
       "Description      object\n",
       "AdoptionSpeed     int64\n",
       "PID               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'AdoptionSpeed'\n",
    "nlabels = dataset[target_col].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.countplot(dataset.AdoptionSpeed, color='blue')\n",
    "seaborn.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "\n",
    "Why not to use feature_columns https://github.com/tensorflow/tensorflow/issues/27895\n",
    "\n",
    "feature_columns doc 2.0 https://www.tensorflow.org/api_docs/python/tf/feature_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando las representaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una serie de variables categóricas y ordinales que pueden ser útiles para predecir la velocidad de adopción. Para cada una de ellas, tenemos que pensar cuál es la mejor forma de pasarla como input a la red. Analizaremos algunas de ellas:\n",
    "\n",
    "  * `Age` es una variable numérica discreta, podemos representarla con una única neurona con el valor original. Es muy importante normalizar este tipo de variables.\n",
    "  * `Gender` es una variable categórica. Como la variable tiene pocos valores, utilizaremos un *one-hot encoding* como representación.\n",
    "  * `Breed1` es una variable categórica que puede tomar muchos valores. Podemos utilizar *one-hot encoding*, lo cual resultará en vectores esparsos de dimensión cercana a 300. Alternativamente, podemos utilizar una capa de embedding para representar sus valores con un vector denso de baja dimesionalidad. Pregunta: ¿qué información podrá capturar este embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que definimos cómo vamos a representar cada una de las columnas, las pre-procesamos para formar un numpy array. En este caso, procesaremos el dataset completo porque estamos seguros de que entrará en memoria. En otros casos, puede ser necesario un pre-procesamiento por batches, o incluso utilizar las funciones de Tensorflow incluidas en el módulo `feature_column`.\n",
    "\n",
    "NOTA: para este ejercicio, intentamos utilizar `feature_column` pero causaba que la loss diverga. La documentación no ha sido totalmente actualizada a Tensorflow 2.0, y puede ser que nos encontremos ante un error de cambio de versiones. Pueden encontrar más ejemplos en [este link](https://www.tensorflow.org/tutorials/structured_data/feature_columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important to always use the same one-hot length\n",
    "one_hot_columns = {\n",
    "    one_hot_col: dataset[one_hot_col].max()\n",
    "    for one_hot_col in ['Gender', 'Color1']\n",
    "}\n",
    "embedded_columns = {\n",
    "    embedded_col: dataset[embedded_col].max() + 1\n",
    "    for embedded_col in ['Breed1']\n",
    "}\n",
    "numeric_columns = ['Age', 'Fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(df):\n",
    "    direct_features = []\n",
    "\n",
    "    # Create one hot encodings\n",
    "    for one_hot_col, max_value in one_hot_columns.items():\n",
    "        direct_features.append(tf.keras.utils.to_categorical(df[one_hot_col] - 1, max_value))\n",
    "    \n",
    "    for numeric_col in numeric_columns:\n",
    "        scaled_col = (df[numeric_col] - df[numeric_col].min()) / (df[numeric_col].max() - df[numeric_col].min())\n",
    "        direct_features.append(scaled_col.values.reshape(-1,1))\n",
    "    \n",
    "    # Concatenate all features that don't need further embedding into a single matrix.\n",
    "    features = {'direct_features': numpy.hstack(direct_features)}\n",
    "\n",
    "    # Create embedding columns - nothing to do here. We will use the zero embedding for OOV\n",
    "    for embedded_col in embedded_columns.keys():\n",
    "        features[embedded_col] = df[embedded_col].values\n",
    "\n",
    "    # Convert labels to one-hot encodings\n",
    "    targets = tf.keras.utils.to_categorical(df[target_col], nlabels)\n",
    "    \n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['direct_features'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_features_input_shape = (X_train['direct_features'].shape[1],)\n",
    "direct_features_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando datasets iterables\n",
    "\n",
    "Como hemos visto, las redes neuronales se entrenan iterativamente con el algoritmo de *stochastic gradient descent*. Una forma de hacerlo es pasarle el dataset entero al método `fit` de un modelo de Keras, como vimos en la notebook anterior. Sin embargo, esto tiene algunas desventajas:\n",
    "\n",
    "* El dataset procesado debe entrar en memoria\n",
    "* El dataset procesado debe entrar en disco, lo cual no siempre es factible para encodings y datasets realmente grandes (ej: la wikipedia)\n",
    "* Una vez que la GPU ha terminado de procesar los datos, devuelve el control a la CPU (que estaba esperando sin hacer nada), y espera a que los nuevos datos son particionados.\n",
    "* No es posible usar cálculo distribuido en distintos file systems.\n",
    "\n",
    "Las dos primeras desventajas se solucionan preprocesando los datos en batches, y creando matrices anchas pero con pocas filas. Sin embargo, escribir este código manualmente puede ser complejo y en general lo hacemos de manera ineficiente. Solucionar las dos últimas es bastante más complicado y a la vez crítico. \n",
    "\n",
    "> **No importa qué tan buen hardware usemos para el entrenamiento del modelo, si seguimos limitados por un procesamiento de datos lineal y single core.**\n",
    "\n",
    "Por eso es recomendable utilizar las abstracciones nativas provistas por Tensorflow que paralelizan internamente muchas funciones.\n",
    "\n",
    "Para ello, crearemos un objeto `tf.data.Dataset` iterable a partir de nuestro dataframe de pandas y no tendremos que preocuparnos por la optimización de la GPU. Los datasets saben cómo crear batches, shuffles, aplicar funciones map y filter, etc. Además, podemos crear datasets a partir de diversas estructuras de datos, como numpy arrays o archivos. Pueden encontrar más información sobre los distintos tipos de Datasets en [este tutorial](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# TODO shuffle the train dataset!\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    process_features(dev_dataset)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 12])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_ds))[0]['direct_features'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver qué es lo que tiene adentro en dataset obteniendo la primera operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'direct_features': <tf.Tensor: id=83, shape=(32, 12), dtype=float64, numpy=\n",
       "  array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.51260504e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.52100840e-01, 8.33333333e-03],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.26050420e-02, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.51260504e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.10084034e-02, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.20168067e-03, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.52941176e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.40336134e-03, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.00000000e+00, 0.00000000e+00, 2.52100840e-02, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.40336134e-03, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.40336134e-03, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.36134454e-02, 3.33333333e-04],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.26050420e-02, 5.00000000e-02],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.20168067e-03, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.26050420e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.20168067e-03, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.10084034e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.40336134e-03, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.20168067e-03, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.26050420e-02, 3.33333333e-02],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.40336134e-03, 3.33333333e-02],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.40336134e-03, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.03361345e-01, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.26050420e-02, 6.66666667e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.26050420e-02, 3.33333333e-02],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.00000000e+00, 5.04201681e-02, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.20168067e-03, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.26050420e-02, 0.00000000e+00],\n",
       "         [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.26050420e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.56302521e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.00000000e+00, 1.68067227e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.68067227e-02, 0.00000000e+00]])>,\n",
       "  'Breed1': <tf.Tensor: id=82, shape=(32,), dtype=int64, numpy=\n",
       "  array([109, 195, 266, 179, 307, 307, 307, 307, 299, 307, 307, 307, 264,\n",
       "         265, 266, 307, 307, 307, 254, 307, 299, 307, 205, 247, 264, 265,\n",
       "         307, 307, 266, 152, 266, 266])>},\n",
       " <tf.Tensor: id=84, shape=(32, 5), dtype=float32, numpy=\n",
       " array([[0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(train_ds))\n",
    "x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo el modelo\n",
    "\n",
    "Construimos el modelo, por ahora con sólo una capa oculta. Sin embargo, la complejidad más grande es combinar los features que tienen embeddings con los que no. Por cada tipo de feature, tenemos que agregar una capa de `Input`. Tener en cuenta que cada embedded feature se considera distinto.\n",
    "\n",
    "Como tenemos más de un input, tenemos que usar la API funcional de Keras en lugar de usar un modelo `Sequential`. La API funcional puede construir modelos más flexibles, ya que conectaremos explícitamente cada capa con su capa siguiente.\n",
    "\n",
    "Pueden encontrar otro ejemplo similar a este código en [esta notebook](https://www.kaggle.com/alexanderkireev/deep-learning-support-9663)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding embedding of size 77 for layer Breed1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nalmeira/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/data_structures.py:669: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(wrapped_dict, collections.Mapping):\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "hidden_layer_size = 64\n",
    "\n",
    "# Add one input and one embedding for each embedded column\n",
    "embedding_layers = []\n",
    "inputs = []\n",
    "for embedded_col, max_value in embedded_columns.items():\n",
    "    input_layer = layers.Input(shape=(1,), name=embedded_col)\n",
    "    inputs.append(input_layer)\n",
    "    # Define the embedding layer\n",
    "    embedding_size = int(max_value / 4)\n",
    "    embedding_layers.append(\n",
    "        tf.squeeze(layers.Embedding(input_dim=max_value, output_dim=embedding_size)(input_layer), axis=-2))\n",
    "    _emb = layers.Embedding(input_dim=max_value, output_dim=embedding_size)(input_layer)\n",
    "    print('Adding embedding of size {} for layer {}'.format(embedding_size, embedded_col))\n",
    "\n",
    "# Add the direct features already calculated\n",
    "direct_features_input = layers.Input(shape=direct_features_input_shape, name='direct_features')\n",
    "inputs.append(direct_features_input)\n",
    "    \n",
    "# Concatenate everything together\n",
    "features = layers.concatenate(embedding_layers + [direct_features_input])\n",
    "\n",
    "dense1 = layers.Dense(hidden_layer_size, activation='relu')(features)\n",
    "output_layer = layers.Dense(nlabels, activation='softmax')(dense1)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de evaluación\n",
    "\n",
    "Al igual que en la materia de aprendizaje supervisado, utilizaremos el accuracy como métrica, y agregaremos el score f1. Es opcional implementar esta predicción como un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "direct_features (InputLayer)    [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 89)           0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 direct_features[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           5760        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            325         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 29,801\n",
      "Trainable params: 29,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 441.50 410.00\" width=\"442pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 437.5,-406 437.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140506680111632 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140506680111632</title>\n",
       "<polygon fill=\"none\" points=\"64,-365.5 64,-401.5 187,-401.5 187,-365.5 64,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"125.5\" y=\"-379.8\">Breed1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140506629902416 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140506629902416</title>\n",
       "<polygon fill=\"none\" points=\"51.5,-292.5 51.5,-328.5 199.5,-328.5 199.5,-292.5 51.5,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"125.5\" y=\"-306.8\">embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 140506680111632&#45;&gt;140506629902416 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140506680111632-&gt;140506629902416</title>\n",
       "<path d=\"M125.5,-365.4551C125.5,-357.3828 125.5,-347.6764 125.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"129.0001,-338.5903 125.5,-328.5904 122.0001,-338.5904 129.0001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140505030433232 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140505030433232</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 251,-255.5 251,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"125.5\" y=\"-233.8\">tf_op_layer_Squeeze: TensorFlowOpLayer</text>\n",
       "</g>\n",
       "<!-- 140506629902416&#45;&gt;140505030433232 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140506629902416-&gt;140505030433232</title>\n",
       "<path d=\"M125.5,-292.4551C125.5,-284.3828 125.5,-274.6764 125.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"129.0001,-265.5903 125.5,-255.5904 122.0001,-265.5904 129.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140505030664016 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140505030664016</title>\n",
       "<polygon fill=\"none\" points=\"161,-146.5 161,-182.5 316,-182.5 316,-146.5 161,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-160.8\">concatenate: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140505030433232&#45;&gt;140505030664016 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140505030433232-&gt;140505030664016</title>\n",
       "<path d=\"M153.4326,-219.4551C168.101,-209.979 186.2556,-198.2508 202.0214,-188.0658\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"203.9966,-190.9566 210.4971,-182.5904 200.1982,-185.0769 203.9966,-190.9566\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140505031019792 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140505031019792</title>\n",
       "<polygon fill=\"none\" points=\"269.5,-219.5 269.5,-255.5 433.5,-255.5 433.5,-219.5 269.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351.5\" y=\"-233.8\">direct_features: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140505031019792&#45;&gt;140505030664016 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140505031019792-&gt;140505030664016</title>\n",
       "<path d=\"M323.5674,-219.4551C308.899,-209.979 290.7444,-198.2508 274.9786,-188.0658\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.8018,-185.0769 266.5029,-182.5904 273.0034,-190.9566 276.8018,-185.0769\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140505030567824 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140505030567824</title>\n",
       "<polygon fill=\"none\" points=\"194,-73.5 194,-109.5 283,-109.5 283,-73.5 194,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-87.8\">dense: Dense</text>\n",
       "</g>\n",
       "<!-- 140505030664016&#45;&gt;140505030567824 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140505030664016-&gt;140505030567824</title>\n",
       "<path d=\"M238.5,-146.4551C238.5,-138.3828 238.5,-128.6764 238.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"242.0001,-119.5903 238.5,-109.5904 235.0001,-119.5904 242.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140505030430992 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140505030430992</title>\n",
       "<polygon fill=\"none\" points=\"187.5,-.5 187.5,-36.5 289.5,-36.5 289.5,-.5 187.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140505030567824&#45;&gt;140505030430992 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140505030567824-&gt;140505030430992</title>\n",
       "<path d=\"M238.5,-73.4551C238.5,-65.3828 238.5,-55.6764 238.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"242.0001,-46.5903 238.5,-36.5904 235.0001,-46.5904 242.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, dpi=72).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo\n",
    "\n",
    "Una vez que tenemos definido nuestro modelo, tenemos que entrenarlo. Sin embargo, para que los resultados sean útiles, tenemos que llevar un registro de qué hiperparámetros utilizamos y qué performance obtuvimos. Para eso, usaremos [MLFlow](https://mlflow.org/docs/latest/quickstart.html), una librería muy simple pero que permite sistematizar el registro de resultados.\n",
    "\n",
    "MLFlow soporta muchísimos casos de uso, pero por ahora sólo usaremos el más básico de todos para organizar el entrenamiento. Llamaremos *experiments* a los cambios grandes en la arquitectura, por ejemplo, si agregamos muchas capas nuevas o mecanismos de regularización. Llamaremos *runs* a las distintas ejecuciones de la misma arquitectura donde variamos sólo algunos hiperparámetros, como funciones de activación, cantidad de neuronas, tamaños de los embeddings, etc.\n",
    "\n",
    "Para acceder a la interfaz gráfica donde podemos ver las *run*, en una nueva terminal tenemos que ejecutar \n",
    "\n",
    "    $ mlflow ui -p PORT\n",
    "    \n",
    "Y abrir `https://localhost:PORT` en nuestro navegador (donde `PORT` es un número de puerto). Si estamos en un servidor, es probab, tendremos que abrir un nuevo puerto ssh a `PORT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "265/265 [==============================] - 6s 24ms/step - loss: 1.4633 - accuracy: 0.3083\n",
      "Epoch 2/10\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 1.4299 - accuracy: 0.3343\n",
      "Epoch 3/10\n",
      "265/265 [==============================] - 3s 11ms/step - loss: 1.4183 - accuracy: 0.3428\n",
      "Epoch 4/10\n",
      "265/265 [==============================] - 4s 17ms/step - loss: 1.4089 - accuracy: 0.3481\n",
      "Epoch 5/10\n",
      "265/265 [==============================] - 4s 16ms/step - loss: 1.4005 - accuracy: 0.3529\n",
      "Epoch 6/10\n",
      "265/265 [==============================] - 4s 17ms/step - loss: 1.3935 - accuracy: 0.3601\n",
      "Epoch 7/10\n",
      "265/265 [==============================] - 4s 16ms/step - loss: 1.3873 - accuracy: 0.3648\n",
      "Epoch 8/10\n",
      "265/265 [==============================] - 4s 16ms/step - loss: 1.3819 - accuracy: 0.3688\n",
      "Epoch 9/10\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 1.3771 - accuracy: 0.3719\n",
      "Epoch 10/10\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 1.3729 - accuracy: 0.3738\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 1.4434 - accuracy: 0.3222\n",
      "*** Test loss: 1.443443675539387 - accuracy: 0.3221539855003357\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('very_base_approach_2')\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    # Log model hiperparameters first\n",
    "    mlflow.log_param('hidden_layer_size', hidden_layer_size)\n",
    "    mlflow.log_param('embedded_columns', embedded_columns)\n",
    "    mlflow.log_param('one_hot_columns', one_hot_columns)\n",
    "    # mlflow.log_param('numerical_columns', numerical_columns)  # Not using these yet\n",
    "    \n",
    "    # Train\n",
    "    epochs = 10\n",
    "    history = model.fit(train_ds, epochs=epochs)\n",
    "    \n",
    "    for epoch, loss, accuracy in zip(history.epoch, history.history['loss'], history.history['accuracy']):\n",
    "        mlflow.log_metric('epoch', epoch)\n",
    "        mlflow.log_metric('loss', loss)\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, accuracy = model.evaluate(test_ds)\n",
    "    print(\"*** Test loss: {} - accuracy: {}\".format(loss, accuracy))\n",
    "    mlflow.log_metric('epochs', epochs)\n",
    "    mlflow.log_metric('dev_loss', loss)\n",
    "    mlflow.log_metric('dev_accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando del modelo\n",
    "\n",
    "Además de tener en cuenta las métricas de performance del modelo, es importante mirar los resultados obtenidos y controlar que el modelo efectivamente está aprendiendo algo relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nalmeira/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:364: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if isinstance(inputs, collections.Sequence):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc9e051fdd0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = numpy.argmax(model.predict(test_ds), axis=1)\n",
    "seaborn.countplot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, ..., 2, 4, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_chief_worker_only',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " 'epoch',\n",
       " 'history',\n",
       " 'model',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_predict_batch_begin',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_begin',\n",
       " 'on_predict_end',\n",
       " 'on_test_batch_begin',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_begin',\n",
       " 'on_test_end',\n",
       " 'on_train_batch_begin',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'params',\n",
       " 'set_model',\n",
       " 'set_params',\n",
       " 'validation_data']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3b65c24f56bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history = model.fit(train_ds, epochs=epochs,\n\u001b[0m\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     callbacks=[tensorboard_callback])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train\n",
    "epochs = 10\n",
    "history = model.fit(train_ds, epochs=epochs,\n",
    "                    validation_data=test_ds,\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"*** Test loss: {} - accuracy: {}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20370), started 21:40:43 ago. (Use '!kill 20370' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/nalmeira/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorboard/notebook.py:416: DeprecationWarning: cgi.escape is deprecated, use html.escape instead\n",
      "  (\"%HTML_ID%\", cgi.escape(frame_id, quote=True)),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f4c58f7d3c3ceddc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f4c58f7d3c3ceddc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({direct_features: (None, 10), Breed1: (None,)}, (None, 5)), types: ({direct_features: tf.float32, Breed1: tf.int64}, tf.float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({direct_features: (None, 10), Breed1: (None,)}, (None, 5)), types: ({direct_features: tf.float32, Breed1: tf.int64}, tf.float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train.shuffle(1000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "        description='Training a MLP on the petfinder dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--dataset_dir'], dest='dataset_dir', nargs=None, const=None, default='../petfinder_dataset', type=<class 'str'>, choices=None, help='Directory with the training and test files.', metavar=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--dataset_dir', default='../petfinder_dataset', type=str,\n",
    "                        help='Directory with the training and test files.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--batch_size'], dest='batch_size', nargs=None, const=None, default=32, type=<class 'int'>, choices=None, help='Number of instances in each batch.', metavar=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                        help='Number of instances in each batch.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(['--batch_size', '32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get_args',\n",
       " '_get_kwargs',\n",
       " 'batch_size',\n",
       " 'dataset_dir']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_action_groups',\n",
       " '_actions',\n",
       " '_add_action',\n",
       " '_add_container_actions',\n",
       " '_check_conflict',\n",
       " '_check_value',\n",
       " '_defaults',\n",
       " '_get_args',\n",
       " '_get_formatter',\n",
       " '_get_handler',\n",
       " '_get_kwargs',\n",
       " '_get_nargs_pattern',\n",
       " '_get_option_tuples',\n",
       " '_get_optional_actions',\n",
       " '_get_optional_kwargs',\n",
       " '_get_positional_actions',\n",
       " '_get_positional_kwargs',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_handle_conflict_error',\n",
       " '_handle_conflict_resolve',\n",
       " '_has_negative_number_optionals',\n",
       " '_match_argument',\n",
       " '_match_arguments_partial',\n",
       " '_mutually_exclusive_groups',\n",
       " '_negative_number_matcher',\n",
       " '_option_string_actions',\n",
       " '_optionals',\n",
       " '_parse_known_args',\n",
       " '_parse_optional',\n",
       " '_pop_action_class',\n",
       " '_positionals',\n",
       " '_print_message',\n",
       " '_read_args_from_files',\n",
       " '_registries',\n",
       " '_registry_get',\n",
       " '_remove_action',\n",
       " '_subparsers',\n",
       " 'add_argument',\n",
       " 'add_argument_group',\n",
       " 'add_help',\n",
       " 'add_mutually_exclusive_group',\n",
       " 'add_subparsers',\n",
       " 'allow_abbrev',\n",
       " 'argument_default',\n",
       " 'conflict_handler',\n",
       " 'convert_arg_line_to_args',\n",
       " 'description',\n",
       " 'epilog',\n",
       " 'error',\n",
       " 'exit',\n",
       " 'format_help',\n",
       " 'format_usage',\n",
       " 'formatter_class',\n",
       " 'fromfile_prefix_chars',\n",
       " 'get_default',\n",
       " 'parse_args',\n",
       " 'parse_intermixed_args',\n",
       " 'parse_known_args',\n",
       " 'parse_known_intermixed_args',\n",
       " 'prefix_chars',\n",
       " 'print_help',\n",
       " 'print_usage',\n",
       " 'prog',\n",
       " 'register',\n",
       " 'set_defaults',\n",
       " 'usage']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5_0.3'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [0.5, 0.3]\n",
    "\n",
    "'_'.join(map(str, lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f39106a9990>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.countplot(numpy.argmax(model.predict(test_ds), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3918427590>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = 'batch_size__32__epochs__10__hidden_layer_sizes__100__dropout__0.5'\n",
    "subs_dir = os.path.join('submissions', experiment)\n",
    "input_csv = os.path.join(subs_dir, 'submit.csv')\n",
    "preds = pd.read_csv(input_csv)\n",
    "seaborn.countplot(preds.AdoptionSpeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.463194534487085,\n",
       "  1.430027775136381,\n",
       "  1.4184244729045996,\n",
       "  1.408985713495704,\n",
       "  1.4006267965156793,\n",
       "  1.39353327245594,\n",
       "  1.3873380327534548,\n",
       "  1.381965470919578,\n",
       "  1.3771606248155968,\n",
       "  1.3729566977563443],\n",
       " 'accuracy': [0.30832842,\n",
       "  0.33431777,\n",
       "  0.3428234,\n",
       "  0.3481394,\n",
       "  0.35286474,\n",
       "  0.36007088,\n",
       "  0.36479622,\n",
       "  0.36881277,\n",
       "  0.37188423,\n",
       "  0.37377438]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
